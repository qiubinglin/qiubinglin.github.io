---
layout:     post
title:      "CPU Cache"
date:       2025-07-05 16:00:00
author:     "Bing"
catalog:    true
tags:
    - CPU
    - Computer Architecture
    - Cache
---

本文主要介绍CPU Cache的结构组织方式，以及如何支持高速的数据访问需求。Cache作为CPU和主存之间的桥梁，其设计直接影响着系统的整体性能。

# 1. 组相联（Set-Associative）架构

一言蔽之，Cache被划分成多个组（Set），每个组被划分成多个路（Way）缓存行。

## 1.1 缓存行（Cache Line）
缓存行是Cache的基本访存单元和存储单元，通常为32/64字节，每个Line存储一段主存数据。缓存行的大小是Cache设计的关键参数，需要在空间利用率和访问效率之间找到平衡。

## 1.2 什么是组（Set）
每一个地址都会被映射到一个组，即有一个映射函数 $F$ 使得 $F(addr) \to group$（通常是根据地址的中间几位索引）。每个组存储着n个缓存行，称为n路组相联（n-way set-associative）。

## 1.3 什么是路（Way）
一个组内的每一"行"就叫做一"路"。映射入组内的地址会和每一路的tag比较确定数据是否在Cache内。路数越多，Cache的灵活性越高，但硬件复杂度也相应增加。

# 2. Cache地址解析与访问机制

## 2.1 地址构成
我们先来理解一个地址在Cache的视角中的构成：

```
[                Address bits                ]
[        Tag bits        ][ Index bits ][ Line Offset bits ]
```

| 字段名 | 作用 | 来自地址的哪部分 | 位数计算 |
|--------|------|------------------|----------|
| Line Offset（行内偏移） | 表示该地址在cache line中的字节偏移 | 地址最低位 | log₂(Line Size) |
| Index / Set Index（组索引） | 决定该地址落入cache中哪一组（set） | 地址中间位 | log₂(Cache sets数量) |
| Tag（标记） | 用于验证cache行是否是所需地址 | 移除Line offset和Index的剩余位 | 地址位数 - Index位数 - Line Offset位数 |

### 2.1.1 Line Offset
- **作用**：确定你要访问的这个block内部的哪一个字节
- **示例**：如果Line大小是64字节，需要6 bits来表示偏移（2^6 = 64）
- **位数**：Line Offset位数 = log₂(Line Size)

### 2.1.2 Index
- **作用**：决定这个地址应该映射到Cache中的哪一组（Set）
- **原理**：Cache被划分为多个组，每个组包含若干个块（ways）
- **位数**：Index位数 = log₂(Cache sets数量)

### 2.1.3 Tag
- **作用**：为了确认这个地址是否真的存在于Cache中
- **原理**：因为多个地址可能映射到同一组，所以需要用Tag来区分
- **匹配**：每个Cache Line都保存一个Tag，如果地址的Tag匹配则命中，否则Miss

## 2.2 缓存行状态位
缓存行除了存储数据外，还包含重要的状态信息：

- **Valid位**：标识当前缓存行是否真正存储着有效数据
- **Dirty位**：标识是否为脏数据（与主存不一致）
- **LRU位**：用于替换算法的最近使用信息

## 2.3 缓存寻址方式

| 缓存类型 | 寻址方式 | 优点 | 缺点 | 应用场景 |
|----------|----------|------|------|----------|
| PIPT (Physically Indexed, Physically Tagged) | 使用物理地址索引，物理地址匹配标签 | 安全，无别名问题 | 速度较慢，需要先完成地址转换（TLB） | 对安全性要求高的系统 |
| VIPT (Virtually Indexed, Physically Tagged) | 使用虚拟地址索引，物理地址匹配标签 | 在页大小≥cache行数时可避免alias问题 | 可能存在别名问题 | 现代CPU最常用 |
| VIVT (Virtually Indexed, Virtually Tagged) | 使用虚拟地址索引，虚拟地址匹配标签 | 速度最快 | 容易出现alias和安全问题 | 基本被淘汰 |

## 2.4 数据访问流程

```
1. 地址解析 -> 提取Index和Tag
2. 根据Index定位Set
3. 并行比较Set内所有Way的Tag
4. 命中处理 / 未命中处理
5. 未命中时执行替换算法 -> 驱逐选中缓存行 -> 加载新数据
```

# 3. 替换算法（Replacement Algorithm）

## 3.1 LRU (Least Recently Used)
**核心思想**：替换掉最长时间没有被访问的缓存行。

**实现方式**：为每个缓存行维护一个时间戳或计数器，记录最后访问时间。

**优点**：理论上能获得最优的命中率。

**缺点**：硬件实现复杂，需要维护精确的访问顺序信息。

## 3.2 PLRU (Pseudo-LRU)
**核心思想**：通过维护一个二叉树状的状态位来近似跟踪访问顺序。

**特点**：
- 不严格保证替换绝对最久未使用的行
- 以较低的开销选择一个较长时间未被访问的行
- 硬件实现相对简单

**应用**：现代CPU中广泛使用，在性能和复杂度之间取得良好平衡。

## 3.3 其他替换算法
- **FIFO (First In First Out)**：先进先出，实现简单但性能一般
- **Random**：随机替换，实现最简单但性能最差
- **LFU (Least Frequently Used)**：替换使用频率最低的缓存行

# 4. 缓存一致性（Cache Coherence）

缓存一致性确保**多个缓存中同一地址的数据保持一致**。

## 4.1 一致性原则
- **单一写入原则（Write Serialization）**：所有核心观察到写入操作的顺序必须一致
- **写后读顺序一致性**：如果一个核心写入某地址，后续自己读到的一定是它刚写的值
- **传播原则（Propagation）**：所有写入最终必须传播到所有核心的缓存或主存

## 4.2 MESI协议
MESI是经典的缓存一致性协议，定义了缓存行的四种状态：

| 状态 | 全称 | 含义 | 特点 |
|------|------|------|------|
| M | Modified | 该Cache line已被修改，主存是旧值，只有我有它 | 独占，需要写回主存 |
| E | Exclusive | 和主存一致，只有我有 | 独占，可直接修改 |
| S | Shared | 和主存一致，可能其他核心也有 | 共享，修改前需通知其他核心 |
| I | Invalid | 无效状态，不能使用 | 需要从主存或其他缓存获取 |

## 4.3 状态转换示例
```
I -> E: 读取未缓存的数据
E -> M: 写入独占数据
M -> S: 其他核心读取该数据
S -> I: 其他核心写入该数据
```

## 4.4 性能优化考虑
保持缓存一致性需要耗费时间，因此要尽量降低缓存一致性的流量。常见的性能热点包括：

### 伪共享（False Sharing）
**定义**：多个线程访问不同变量，但这些变量共享在同一个Cache Line上。

**问题**：导致不必要的缓存一致性流量，严重影响性能。

**解决方案**：
- 数据结构填充（Padding）
- 使用线程本地存储
- 重新组织数据结构

# 5. Cache类型与策略

## 5.1 写策略分类

### Write-back Cache
- **特点**：当CPU修改缓存中的数据时，只修改缓存中的副本，不立即写入主存
- **优势**：减少主存访问，提高性能
- **劣势**：数据丢失风险，需要额外的脏位管理
- **应用**：现代CPU的L1/L2 Cache

### Write-through Cache
- **特点**：CPU写入时同时更新缓存和主存
- **优势**：数据一致性好，实现简单
- **劣势**：主存访问频繁，性能较低
- **应用**：对一致性要求极高的系统

## 5.2 其他分类方式

### 按级数分类
- **L1 Cache**：速度最快，容量最小，通常分离指令和数据
- **L2 Cache**：中等速度和容量，通常统一指令和数据
- **L3 Cache**：速度较慢，容量最大，多核共享

### 按映射方式分类
- **直接映射**：每个地址只能映射到一个固定位置
- **全相联**：每个地址可以映射到任意位置
- **组相联**：介于两者之间，平衡了性能和复杂度

# 6. 性能优化实践

## 6.1 空间局部性优化
- 合理组织数据结构，让相关数据在内存中连续存储
- 使用数组而非链表（在可能的情况下）
- 避免随机访问模式

## 6.2 时间局部性优化
- 重用已加载的数据
- 循环优化，减少不必要的内存访问
- 使用缓存友好的算法

## 6.3 预取技术
- **硬件预取**：CPU自动预取相邻数据
- **软件预取**：使用预取指令提示CPU
- **流式预取**：针对顺序访问模式的优化


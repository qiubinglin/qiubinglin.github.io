---
layout:     post
title:      "CPU Cache"
date:       2025-07-05 16:00:00
author:     "Bing"
catalog:    true
tags:
    - CPU
---

本文主要介绍Cache的结构是如何组织的，怎么支持高速的数据访问需求。
  
# 组相联（Set-Associative）架构
一言蔽之，Cache被划分成多个组（Set），每个组被划分成多个路（Way）缓存行。

## 缓存行（Cache line）
缓存行是Cache的基本访存单元和存储单元，通常为 32/64 bytes，每个 Line 存储一段主存数据。

## 什么是组（Set）
每一个地址都会被映射到一个组，即有一个映射函数 $F$ 使得 $F(addr) \to group$（通常是根据地址的中间几位索引）。每个组存储着 n 个缓存行，称为 n 路组相联（n-way set-associative）。

## 什么是路（Way）
一个组内的每一“行”就叫做一“路”。映射入组内的地址会和每一路的 tag 比较确定数据是否在Cache内。

# Cache怎么处理数据访问
## 理解地址
我们先来理解一个地址在Cache的视角中的构成是怎么样的：
```
[                Address bits                ]
            [ Index bits ][ Line Offset bits ]
[        Tag bits        ]
```

|字段名|作用|来自地址的哪部分|
|-|-|-|
|Line Offset（行内偏移）|表示该地址在 cache line 中的字节偏移|地址最低位|
|Index / Set Index（组索引）|决定该地址落入 cache 中哪一组（set）|地址中间位|
|Tag（标记）|用于验证 cache 行是否是所需地址|移除Line offset的剩余位|

### Line offset
作用：确定你要访问的这个 block 内部的哪一个字节

每个 Cache Line 包含多个字节（如 64B）

如果 Line 大小是 64 字节 → 需要 6 bits 来表示偏移（2^6 = 64）

Line Offset 位数 = log₂(Line Size)

### Index
作用：决定这个地址应该映射到 Cache 中的哪一组（Set）

Cache 被划分为多个组，每个组包含若干个块（ways）

Index 从地址中提取出 组号

Index 位数 = log₂(Cache sets 数量)

### Tag
作用：为了确认这个地址是否真的存在于 Cache 中

因为多个地址可能映射到同一组，所以需要用 Tag 来区分

每个 Cache Line 都保存一个 Tag，如果地址的 Tag 匹配 → 命中，否则 → Miss

### Valid and Dirty
缓存行保存的 Tag 中的最高两位分别是 Valid 位和 Dirty 位。
* Valid：标识当前缓存行是否真正存储着有效数据
* Dirty：标识是否为脏数据

## 缓存寻址方式
| 缓存类型                                             | 寻址方式                   | 描述                                   |
| ------------------------------------------------ | ---------------------- | ------------------------------------ |
| **PIPT** (Physically Indexed, Physically Tagged) | 使用 **物理地址索引**，物理地址匹配标签 | 安全但速度较慢，因为必须先完成地址转换（TLB）才能访问 cache   |
| **VIPT** (Virtually Indexed, Physically Tagged)  | 使用 **虚拟地址索引**，物理地址匹配标签 | 在页大小 ≥ cache 行数时，可以避免 alias 问题；最常用   |
| **VIVT** (Virtually Indexed, Virtually Tagged)   | 使用 **虚拟地址索引**，虚拟地址匹配标签 | 速度最快但容易出现 alias（别名）和安全问题，现代 CPU 基本淘汰 |


## 数据访问的详细流程
```
解析地址确定组索引 -> 遍历比较地址tag与组内缓存行的tag -> 命中处理/未命中处理

未命中 -> 根据替换算法选出替换出的缓存行 -> 驱逐选中缓存行 -> 存储或读入所需缓存行数据
```

# Replacement Algorithm
## LRU (Least Recently Used)
LRU算法的核心思想是：替换掉最长时间没有被访问的缓存行。

## PLRU (Pseudo-LRU)
PLRU 通过维护一个二叉树状的状态位来近似跟踪哪些缓存行是最近使用的，哪些是较久未使用的。它不严格保证替换绝对最久未使用的行，而是以较低的开销选择一个较长时间未被访问的行进行替换。

# 缓存一致性协议
一致性原则：
* 读一致性（Read Coherence）：所有处理器最终读取到一致的数据
* 写传播（Write Propagation）：一个核心对共享数据的修改，其他核心能感知
* 写串行化（Write Serialization）：多个写操作对同一地址的顺序一致
* 原子性（Atomicity）单个核心的读写操作不能被拆分（如读到的值不能是“半新半旧”）

## MESI 协议
| 状态    | 全称        | 含义                            |
| ----- | --------- | ----------------------------- |
| M | Modified  | 该 Cache line 已被修改，主存是旧值，只有我有它 |
| E | Exclusive | 和主存一致，只有我有                    |
| S | Shared    | 和主存一致，可能其他核心也有                |
| I | Invalid   | 无效状态，不能使用                     |

## 缓存一致性协议在HPC中的体现
显然，保持缓存的一致性需要耗费时间，因此要尽量降低缓存一致性的流量。以下是常见的性能热点：
* 伪共享（False Sharing）
False Sharing 是指多个线程访问不同变量，但这些变量共享在同一个 Cache Line 上，导致不必要的缓存一致性流量，从而严重影响性能。

# Category
* Write-back Cache 现代主流
* Write-through Cache
